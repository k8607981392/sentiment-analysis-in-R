library(twitteR)
consumerKey <- "ES6sebmcdWIP1S70gEirYbZri"
consumerSecret <- "ZtUqF5dYaMs5riHZCNzZOn3VL1IQQxrzSJ0HfQzNlByylOCzlg"
accessToken <- "2853768842-t25cpC4Ve9KcDgVTqwZqVIwdXRSeLD0xdkGloy1"
accessTokenSecret <- "ErITskWUTUAvZsHW7IzLueGqeEcDMlkHymdhFAFRRotMs"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)
tweets_geolocated <- searchTwitter("#Demonitization", n=1000, lang="en",
geocode = "28.459497,77.026638,500mi",
since = "2016-12-01")
tweets_geolocated.df <- twListToDF(tweets_geolocated)
tweets_geolocated.df[1:5,1:4]
mean(c)
d<-c(42,39,48,60,41)
mean(d)
d<-c(38,42,56,64,68,69,62)
mean(d)
d-5
d-57
sum(d)
d<-c(42,39,48,60,41)
sum(d)
d<-c(110,120,123,132,125)
mean(d)
d<-c(120,118,125,136,121)
mean(d)
twosample <- data.frame(a=c(175,168,168,190,156,181,182,175,174,179),
b=c(185,169,173,173,188,186,175,174,179,180))
var.test(twosample$a,twosample$b)
t.test(twosample$a,twosample$b, var.equal = TRUE)
install.packages("N3")
pair<-read.sas7bdat(file.choose())
library(sas7bdat)
pair<-read.sas7bdat(file.choose())
View(pair)
change<-(pair$Before - pair$After)
change
class(change)
t.test(x=pair$Before,y=pair$After, paire=T)
chi_square<-read.sas7bdat(file.choose())
library(sas7bdat)
chi_square<-read.sas7bdat(file.choose())
chi_square
View(chi_square)
levels(chi_square$Gender)
levels(chi_square$Voting_preferences)
tbl1<-table(chi_square$Gender,chi_square$Voting_preferences)
tbl1
chisq.test(chi_square$Gender,chi_square$Voting_preferences)
chi_sq<-read.sas7bdat(file.choose())
chi_sq
View(chi_sq)
str(chi_sq)
levels(chi_sq$Level_of_Educational_Achievement)
levels(chi_sq$Frequency_of_Readership)
tbl<-table(chi_sq$Frequency_of_Readership,chi_sq$Level_of_Educational_Achievement)
tbl
chisq.test(chi_sq$Frequency_of_Readership,chi_sq$Level_of_Educational_Achievement)
library(foreign)
library(sas7bdat)
class<-read.sas7bdat(file.choose())
class
View(class)
cor(class$Height, class$Weight)
cor.test(x=class$Height,y=class$Weight,method = "pearson")
library(ppcor)
pcor.test(class$Height,class$Weight,class$Age,method = "pearson")
library(rattle)
install.packages("rattle")
library(rattle)
data(wine, package = 'rattle')
library(rattle)
install.packages("rattle")
library(rattle)
update()
update(R)
update(R)
updateR()
install.packages('installr')
library('installr')
library('installr')
updateR()
updateR()
library('installr')
updateR()
library(rattle)
install.packages('rattle')
library(rattle)
install.packages("RGtk2Extras")
library(rattle)
data(wine, package = 'rattle')
install.packages('rattle')
library('installr')
updateR()
install.packages("rattle", dependencies = FALSE)
install.packages(c("bindrcpp", "bit64", "boot", "car", "checkmate", "curl", "dplyr", "foreign", "Formula", "glue", "h2o", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "igraph", "irlba", "jsonlite", "MASS", "pROC", "Rcpp", "readr", "RSQLite", "sandwich", "sp", "SparseM", "statmod", "tibble", "tidyr", "tseries", "TTR", "withr", "xts"))
install.packages(c("bindrcpp", "bit64", "boot", "car", "checkmate", "curl", "dplyr", "foreign", "Formula", "glue", "h2o", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "igraph", "irlba", "jsonlite", "MASS", "pROC", "Rcpp", "readr", "RSQLite", "sandwich", "sp", "SparseM", "statmod", "tibble", "tidyr", "tseries", "TTR", "withr", "xts"))
install.packages(c("bindrcpp", "bit64", "boot", "car", "checkmate", "curl", "dplyr", "foreign", "Formula", "glue", "h2o", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "igraph", "irlba", "jsonlite", "MASS", "pROC", "Rcpp", "readr", "RSQLite", "sandwich", "sp", "SparseM", "statmod", "tibble", "tidyr", "tseries", "TTR", "withr", "xts"))
install.packages("rattle", dependencies = FALSE)
library(rattle)
library(twitteR)
consumerKey <- "ES6sebmcdWIP1S70gEirYbZri"
consumerSecret <- "ZtUqF5dYaMs5riHZCNzZOn3VL1IQQxrzSJ0HfQzNlByylOCzlg"
accessToken <- "2853768842-t25cpC4Ve9KcDgVTqwZqVIwdXRSeLD0xdkGloy1"
accessTokenSecret <- "ErITskWUTUAvZsHW7IzLueGqeEcDMlkHymdhFAFRRotMs"
setup_twitter_oauth(consumerKey, consumerSecret, accessToken, accessTokenSecret)
tweets_geolocated <- searchTwitter("#Demonitization", n=1000, lang="en",
geocode = "28.459497,77.026638,500mi",
since = "2016-12-01")
tweets_geolocated.df <- twListToDF(tweets_geolocated)
tweets_geolocated.df[1:5,1:4]
tweets <- searchTwitter("#Demonetization", n=2000, lang="en",
#geocode = "28.459497,77.026638,500mi",
since = "2016-11-08")
tweet_txt = lapply(tweets, function(x) x$getText())
tweet_txt1= twListToDF(tweets)
tweet_txt2 = tweet_txt1[,"text"]
head(tweet_txt)
clean.text <- function(some_txt)
{
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
some_txt = gsub("@\\w+", "", some_txt)
some_txt = gsub("[[:punct:]]", "", some_txt)
some_txt = gsub("[[:digit:]]", "", some_txt)
some_txt = gsub("http\\w+", "", some_txt)
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_txt = gsub("amp", "", some_txt)
# define "tolower error handling" function
try.tolower = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
some_txt = sapply(some_txt, try.tolower)
some_txt = some_txt[some_txt != ""]
names(some_txt) = NULL
some_txt <- strsplit(some_txt," ")
return(some_txt)
}
tweet_clean = clean.text(tweet_txt)
head(tweet_clean,5)
setwd("D:\\WORK!\\Dexlab\\R Extra\\R datasets")
positive=scan('positive-words.txt',what='character',comment.char=';')
setwd("C:/Users/Kuldeep/Desktop/DEXLAB/sentiment analysis")
positive=scan('positive-words.txt',what='character',comment.char=';')
negative=scan('negative-words.txt',what='character',comment.char=';')
positive[30:40]
negative[500:510]
positive=c(positive,"cloud")
negative=negative[negative!="cloud"]
returnpscore=function(t) {
pos.match=match(t,positive)
pos.match=!is.na(pos.match)
pos.score=sum(pos.match)
return(pos.score)
}
positive.score=lapply(tweet_clean,function(x) returnpscore(x))
head(positive.score)
pcount=0
for (i in 1:length(positive.score)) {
pcount=pcount+positive.score[[i]]
}
pcount
returnnscore=function(twet) {
neg.match=match(twet,negative)
neg.match=!is.na(neg.match)
neg.score=sum(neg.match)
return(neg.score)
}
negative.score=lapply(tweet_clean,function(x) returnnscore(x))
ncount=0
for (i in 1:length(negative.score)) {
ncount=ncount+negative.score[[i]]
}
ncount
poswords=function(t){
pmatch=match(t,positive)
posw=positive[pmatch]
posw=posw[!is.na(posw)]
return(posw)
}
negwords=function(t){
nmatch=match(t,negative)
negw=negative[nmatch]
negw=negw[!is.na(negw)]
return(negw)
}
words=NULL
pdatamart=data.frame(words)
for (t in tweet_clean) {
pdatamart=c(poswords(t),pdatamart)
}
head(pdatamart,10)
words=NULL
ndatamart=data.frame(words)
for (t in tweet_clean) {
ndatamart=c(negwords(t),ndatamart)
}
head(ndatamart,10)
pwords <- unlist(pdatamart)
nwords <- unlist(ndatamart)
dpwords=data.frame(table(pwords))
dnwords=data.frame(table(nwords))
library(dplyr)
install.packages("dplyr", dependencies = FALSE)
library(dplyr)
install.packages("dplyr")
library(dplyr)
dpwords = dpwords%>%
mutate(pwords=as.character(pwords))%>%
filter(Freq>10)
dnwords = dnwords%>%
mutate(nwords=as.character(nwords))%>%
filter(Freq>10)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
ggplot(dpwords,aes(pwords,Freq))+
geom_bar(stat="identity",fill="lightblue")+
theme_bw()+
geom_text(aes(pwords,Freq,label=Freq),size=4)+
labs(x="Major Positive Words", y="Frequency of Occurence",
title=paste("Major Positive Words and Occurence in \n '","Demonetization","' twitter feeds, n =",2000))+
geom_text(aes(1,5,label=paste("Total Positive Words :",pcount)),size=4,hjust=0)+
theme(axis.text.x=element_text(angle=45))
ggplot(dnwords,aes(nwords,Freq))+
geom_bar(stat="identity",fill="lightblue")+
theme_bw()+
geom_text(aes(nwords,Freq,label=Freq),size=4)+
labs(x="Major Negative Words", y="Frequency of Occurence",
title=paste("Major Negative Words and Occurence in \n '","Demonetization","' twitter feeds, n =",2000))+
geom_text(aes(1,5,label=paste("Total Negative Words :",ncount)),size=4,hjust=0)+
theme(axis.text.x=element_text(angle=45))
